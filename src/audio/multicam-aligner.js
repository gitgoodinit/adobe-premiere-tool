/**
 * Multi-Camera Audio Aligner
 * Provides clip-level alignment functionality for multi-camera sequences at the audio level
 * Supports manual setup, automatic sync detection, and timeline integration
 */

class MultiCamAudioAligner {
    constructor(audioContext) {
        this.audioContext = audioContext;
        this.sampleRate = audioContext.sampleRate;
        
        // Configuration
        this.config = {
            maxTimeOffset: 10.0,      // Maximum sync offset in seconds
            correlationWindow: 2.0,   // Window size for correlation analysis
            searchResolution: 0.001,  // Search resolution in seconds
            confidenceThreshold: 0.7, // Minimum confidence for auto-sync
            manualOffsetStep: 0.016,  // Manual adjustment step (1 frame at 60fps)
            syncMarkerTolerance: 0.1, // Tolerance for sync markers in seconds
            fftSize: 4096,
            overlapRatio: 0.75
        };
        
        // Camera/track management
        this.cameras = new Map(); // trackId -> camera info
        this.syncGroups = new Map(); // groupId -> sync group info
        this.alignmentData = new Map(); // trackId -> alignment data
        
        // Sync detection state
        this.isSyncAnalyzing = false;
        this.syncProgress = 0;
        
        // Manual alignment state
        this.selectedCamera = null;
        this.referenceCamera = null;
        this.previewMode = false;
        
        // Event handlers
        this.eventHandlers = {
            'syncDetected': [],
            'alignmentChanged': [],
            'syncProgress': [],
            'cameraAdded': [],
            'cameraRemoved': [],
            'groupCreated': []
        };
        
        console.log('Multi-camera audio aligner initialized');
    }
    
    // Camera Management
    addCamera(trackId, options = {}) {\n        const cameraInfo = {\n            trackId,\n            name: options.name || `Camera ${trackId}`,\n            audioBuffer: null,\n            timecode: options.timecode || null,\n            frameRate: options.frameRate || 23.976,\n            recordStartTime: options.recordStartTime || null,\n            syncMarkers: options.syncMarkers || [],\n            isReference: false,\n            active: true,\n            metadata: {\n                resolution: options.resolution || null,\n                codec: options.codec || null,\n                duration: null,\n                channelCount: null\n            }\n        };\n        \n        this.cameras.set(trackId, cameraInfo);\n        \n        // Initialize alignment data\n        this.alignmentData.set(trackId, {\n            offset: 0,\n            confidence: 0,\n            method: 'manual',\n            lastSync: null,\n            syncHistory: [],\n            manualAdjustments: []\n        });\n        \n        this.emit('cameraAdded', { trackId, cameraInfo });\n        \n        console.log(`Camera ${trackId} added:`, cameraInfo.name);\n        return true;\n    }\n    \n    removeCamera(trackId) {\n        const camera = this.cameras.get(trackId);\n        if (!camera) return false;\n        \n        // Remove from any sync groups\n        this.syncGroups.forEach((group, groupId) => {\n            const index = group.cameras.indexOf(trackId);\n            if (index > -1) {\n                group.cameras.splice(index, 1);\n                if (group.cameras.length < 2) {\n                    this.syncGroups.delete(groupId);\n                }\n            }\n        });\n        \n        this.cameras.delete(trackId);\n        this.alignmentData.delete(trackId);\n        \n        this.emit('cameraRemoved', { trackId });\n        \n        console.log(`Camera ${trackId} removed`);\n        return true;\n    }\n    \n    setReferenceCamera(trackId) {\n        // Reset all cameras\n        this.cameras.forEach(camera => {\n            camera.isReference = false;\n        });\n        \n        // Set new reference\n        const camera = this.cameras.get(trackId);\n        if (camera) {\n            camera.isReference = true;\n            this.referenceCamera = trackId;\n            \n            // Reset reference camera's offset to 0\n            const alignment = this.alignmentData.get(trackId);\n            if (alignment) {\n                alignment.offset = 0;\n            }\n            \n            console.log(`Reference camera set to: ${camera.name}`);\n            return true;\n        }\n        return false;\n    }\n    \n    loadAudioForCamera(trackId, audioBuffer) {\n        const camera = this.cameras.get(trackId);\n        if (!camera) {\n            throw new Error(`Camera ${trackId} not found`);\n        }\n        \n        camera.audioBuffer = audioBuffer;\n        camera.metadata.duration = audioBuffer.duration;\n        camera.metadata.channelCount = audioBuffer.numberOfChannels;\n        \n        console.log(`Audio loaded for camera ${trackId}: ${audioBuffer.duration}s`);\n        return true;\n    }\n    \n    // Sync Group Management\n    createSyncGroup(cameras, options = {}) {\n        const groupId = options.groupId || this.generateGroupId();\n        \n        const syncGroup = {\n            id: groupId,\n            name: options.name || `Sync Group ${groupId}`,\n            cameras: [...cameras],\n            referenceCamera: options.referenceCamera || cameras[0],\n            syncMethod: options.syncMethod || 'audio',\n            created: Date.now(),\n            lastSync: null,\n            settings: {\n                autoSync: options.autoSync !== false,\n                syncTolerance: options.syncTolerance || this.config.syncMarkerTolerance,\n                correlationThreshold: options.correlationThreshold || this.config.confidenceThreshold\n            }\n        };\n        \n        this.syncGroups.set(groupId, syncGroup);\n        \n        // Set reference camera for the group\n        this.setReferenceCamera(syncGroup.referenceCamera);\n        \n        this.emit('groupCreated', { groupId, syncGroup });\n        \n        console.log(`Sync group created: ${groupId} with ${cameras.length} cameras`);\n        return groupId;\n    }\n    \n    // Automatic Sync Detection\n    async detectSync(groupId, options = {}) {\n        const group = this.syncGroups.get(groupId);\n        if (!group) {\n            throw new Error(`Sync group ${groupId} not found`);\n        }\n        \n        console.log(`Starting automatic sync detection for group ${groupId}...`);\n        \n        this.isSyncAnalyzing = true;\n        this.syncProgress = 0;\n        \n        const config = { ...this.config, ...options };\n        const results = {};\n        \n        try {\n            // Get reference camera\n            const refCameraId = group.referenceCamera;\n            const refCamera = this.cameras.get(refCameraId);\n            \n            if (!refCamera?.audioBuffer) {\n                throw new Error(`Reference camera ${refCameraId} has no audio loaded`);\n            }\n            \n            const refBuffer = refCamera.audioBuffer.getChannelData(0);\n            \n            // Analyze each camera against reference\n            for (let i = 0; i < group.cameras.length; i++) {\n                const cameraId = group.cameras[i];\n                \n                if (cameraId === refCameraId) {\n                    results[cameraId] = {\n                        offset: 0,\n                        confidence: 1.0,\n                        method: 'reference'\n                    };\n                    continue;\n                }\n                \n                this.syncProgress = (i / group.cameras.length) * 100;\n                this.emit('syncProgress', { groupId, progress: this.syncProgress });\n                \n                const camera = this.cameras.get(cameraId);\n                if (!camera?.audioBuffer) {\n                    console.warn(`Camera ${cameraId} has no audio loaded, skipping`);\n                    continue;\n                }\n                \n                const syncResult = await this.analyzeCameraSync(\n                    refBuffer, \n                    camera.audioBuffer.getChannelData(0),\n                    config\n                );\n                \n                results[cameraId] = {\n                    ...syncResult,\n                    method: 'auto-correlation'\n                };\n            }\n            \n            // Apply results\n            this.applySyncResults(groupId, results);\n            \n            this.syncProgress = 100;\n            group.lastSync = Date.now();\n            \n            this.emit('syncDetected', { groupId, results });\n            \n            console.log('Automatic sync detection completed:', results);\n            return results;\n            \n        } catch (error) {\n            console.error('Sync detection failed:', error);\n            throw error;\n        } finally {\n            this.isSyncAnalyzing = false;\n        }\n    }\n    \n    async analyzeCameraSync(referenceAudio, targetAudio, config) {\n        const refLength = referenceAudio.length;\n        const targetLength = targetAudio.length;\n        \n        const windowSamples = Math.floor(config.correlationWindow * this.sampleRate);\n        const maxOffsetSamples = Math.floor(config.maxTimeOffset * this.sampleRate);\n        const stepSamples = Math.floor(config.searchResolution * this.sampleRate);\n        \n        let bestOffset = 0;\n        let bestCorrelation = -1;\n        \n        // Use multiple analysis windows for robustness\n        const analysisWindows = [\n            { start: Math.floor(refLength * 0.1), name: 'early' },\n            { start: Math.floor(refLength * 0.4), name: 'middle' },\n            { start: Math.floor(refLength * 0.7), name: 'late' }\n        ];\n        \n        const windowResults = [];\n        \n        for (const window of analysisWindows) {\n            const startSample = window.start;\n            const endSample = Math.min(startSample + windowSamples, refLength);\n            \n            if (endSample - startSample < windowSamples / 2) {\n                continue; // Skip if window is too small\n            }\n            \n            const refWindow = referenceAudio.slice(startSample, endSample);\n            const windowResult = await this.crossCorrelateWindow(\n                refWindow, targetAudio, maxOffsetSamples, stepSamples\n            );\n            \n            windowResults.push({\n                ...windowResult,\n                windowName: window.name,\n                windowStart: startSample / this.sampleRate\n            });\n        }\n        \n        // Find best result across all windows\n        if (windowResults.length > 0) {\n            const bestResult = windowResults.reduce((best, current) => \n                current.correlation > best.correlation ? current : best\n            );\n            \n            bestOffset = bestResult.offset;\n            bestCorrelation = bestResult.correlation;\n        }\n        \n        // Additional validation using spectral similarity\n        const spectralConfidence = await this.validateSyncWithSpectral(\n            referenceAudio, targetAudio, bestOffset, config\n        );\n        \n        const finalConfidence = (bestCorrelation * 0.7) + (spectralConfidence * 0.3);\n        \n        return {\n            offset: bestOffset / this.sampleRate,\n            confidence: Math.max(0, Math.min(1, finalConfidence)),\n            correlation: bestCorrelation,\n            spectralSimilarity: spectralConfidence,\n            windowResults\n        };\n    }\n    \n    async crossCorrelateWindow(referenceWindow, targetAudio, maxOffsetSamples, stepSamples) {\n        let bestOffset = 0;\n        let bestCorrelation = -1;\n        \n        const windowLength = referenceWindow.length;\n        \n        for (let offset = -maxOffsetSamples; offset <= maxOffsetSamples; offset += stepSamples) {\n            const targetStart = Math.max(0, offset);\n            const targetEnd = Math.min(targetAudio.length, targetStart + windowLength);\n            \n            const refStart = Math.max(0, -offset);\n            const refEnd = Math.min(windowLength, refStart + (targetEnd - targetStart));\n            \n            if (refEnd - refStart < windowLength / 2) {\n                continue; // Skip if overlap is too small\n            }\n            \n            const refSegment = referenceWindow.slice(refStart, refEnd);\n            const targetSegment = targetAudio.slice(targetStart, targetEnd);\n            \n            const correlation = this.calculateNormalizedCorrelation(refSegment, targetSegment);\n            \n            if (correlation > bestCorrelation) {\n                bestCorrelation = correlation;\n                bestOffset = offset;\n            }\n        }\n        \n        return {\n            offset: bestOffset,\n            correlation: bestCorrelation\n        };\n    }\n    \n    calculateNormalizedCorrelation(signal1, signal2) {\n        const length = Math.min(signal1.length, signal2.length);\n        \n        if (length === 0) return 0;\n        \n        // Calculate means\n        let mean1 = 0, mean2 = 0;\n        for (let i = 0; i < length; i++) {\n            mean1 += signal1[i];\n            mean2 += signal2[i];\n        }\n        mean1 /= length;\n        mean2 /= length;\n        \n        // Calculate correlation\n        let correlation = 0;\n        let variance1 = 0, variance2 = 0;\n        \n        for (let i = 0; i < length; i++) {\n            const diff1 = signal1[i] - mean1;\n            const diff2 = signal2[i] - mean2;\n            \n            correlation += diff1 * diff2;\n            variance1 += diff1 * diff1;\n            variance2 += diff2 * diff2;\n        }\n        \n        const denominator = Math.sqrt(variance1 * variance2);\n        return denominator > 0 ? correlation / denominator : 0;\n    }\n    \n    async validateSyncWithSpectral(refAudio, targetAudio, offsetSamples, config) {\n        const windowSize = 2048;\n        const hopSize = 512;\n        \n        const refStart = Math.max(0, Math.floor(refAudio.length * 0.4));\n        const targetStart = Math.max(0, refStart + offsetSamples);\n        \n        if (targetStart >= targetAudio.length || refStart >= refAudio.length) {\n            return 0;\n        }\n        \n        const refSpectrum = this.calculateSpectrum(\n            refAudio.slice(refStart, refStart + windowSize)\n        );\n        const targetSpectrum = this.calculateSpectrum(\n            targetAudio.slice(targetStart, Math.min(targetStart + windowSize, targetAudio.length))\n        );\n        \n        return this.calculateSpectralSimilarity(refSpectrum, targetSpectrum);\n    }\n    \n    calculateSpectrum(audioData) {\n        // Simple spectral analysis - in production, use proper FFT\n        const spectrum = new Array(audioData.length / 2);\n        \n        for (let k = 0; k < spectrum.length; k++) {\n            let real = 0, imag = 0;\n            \n            for (let n = 0; n < audioData.length; n++) {\n                const angle = -2 * Math.PI * k * n / audioData.length;\n                real += audioData[n] * Math.cos(angle);\n                imag += audioData[n] * Math.sin(angle);\n            }\n            \n            spectrum[k] = Math.sqrt(real * real + imag * imag);\n        }\n        \n        return spectrum;\n    }\n    \n    calculateSpectralSimilarity(spectrum1, spectrum2) {\n        const length = Math.min(spectrum1.length, spectrum2.length);\n        if (length === 0) return 0;\n        \n        let similarity = 0;\n        let totalMagnitude = 0;\n        \n        for (let i = 0; i < length; i++) {\n            const mag1 = spectrum1[i];\n            const mag2 = spectrum2[i];\n            const maxMag = Math.max(mag1, mag2);\n            \n            if (maxMag > 0) {\n                similarity += Math.min(mag1, mag2) / maxMag;\n                totalMagnitude += 1;\n            }\n        }\n        \n        return totalMagnitude > 0 ? similarity / totalMagnitude : 0;\n    }\n    \n    applySyncResults(groupId, results) {\n        const group = this.syncGroups.get(groupId);\n        if (!group) return;\n        \n        Object.entries(results).forEach(([cameraId, result]) => {\n            const trackId = parseInt(cameraId);\n            const alignment = this.alignmentData.get(trackId);\n            \n            if (alignment) {\n                alignment.offset = result.offset;\n                alignment.confidence = result.confidence;\n                alignment.method = result.method;\n                alignment.lastSync = Date.now();\n                \n                alignment.syncHistory.push({\n                    timestamp: Date.now(),\n                    offset: result.offset,\n                    confidence: result.confidence,\n                    method: result.method\n                });\n                \n                // Keep only last 10 sync attempts\n                if (alignment.syncHistory.length > 10) {\n                    alignment.syncHistory.shift();\n                }\n                \n                this.emit('alignmentChanged', {\n                    trackId,\n                    offset: result.offset,\n                    confidence: result.confidence,\n                    method: result.method\n                });\n            }\n        });\n    }\n    \n    // Manual Alignment\n    setManualOffset(trackId, offsetSeconds) {\n        const alignment = this.alignmentData.get(trackId);\n        if (!alignment) return false;\n        \n        const oldOffset = alignment.offset;\n        alignment.offset = offsetSeconds;\n        alignment.method = 'manual';\n        alignment.confidence = 1.0; // Manual adjustments have full confidence\n        \n        alignment.manualAdjustments.push({\n            timestamp: Date.now(),\n            oldOffset,\n            newOffset: offsetSeconds,\n            change: offsetSeconds - oldOffset\n        });\n        \n        this.emit('alignmentChanged', {\n            trackId,\n            offset: offsetSeconds,\n            confidence: 1.0,\n            method: 'manual'\n        });\n        \n        console.log(`Manual offset set for camera ${trackId}: ${offsetSeconds}s`);\n        return true;\n    }\n    \n    adjustOffset(trackId, deltaSeconds) {\n        const alignment = this.alignmentData.get(trackId);\n        if (!alignment) return false;\n        \n        const newOffset = alignment.offset + deltaSeconds;\n        return this.setManualOffset(trackId, newOffset);\n    }\n    \n    nudgeOffset(trackId, direction) {\n        const step = direction > 0 ? this.config.manualOffsetStep : -this.config.manualOffsetStep;\n        return this.adjustOffset(trackId, step);\n    }\n    \n    // Sync Markers\n    addSyncMarker(trackId, timeSeconds, options = {}) {\n        const camera = this.cameras.get(trackId);\n        if (!camera) return false;\n        \n        const marker = {\n            id: options.id || this.generateMarkerId(),\n            time: timeSeconds,\n            name: options.name || `Sync ${camera.syncMarkers.length + 1}`,\n            type: options.type || 'clap',\n            confidence: options.confidence || 1.0,\n            created: Date.now(),\n            verified: options.verified || false\n        };\n        \n        camera.syncMarkers.push(marker);\n        camera.syncMarkers.sort((a, b) => a.time - b.time);\n        \n        console.log(`Sync marker added to camera ${trackId} at ${timeSeconds}s`);\n        return marker.id;\n    }\n    \n    syncBySyncMarkers(groupId) {\n        const group = this.syncGroups.get(groupId);\n        if (!group) return false;\n        \n        console.log(`Syncing by sync markers for group ${groupId}...`);\n        \n        const refCameraId = group.referenceCamera;\n        const refCamera = this.cameras.get(refCameraId);\n        \n        if (!refCamera || refCamera.syncMarkers.length === 0) {\n            console.warn('Reference camera has no sync markers');\n            return false;\n        }\n        \n        const refMarker = refCamera.syncMarkers[0]; // Use first marker as reference\n        const results = {};\n        \n        group.cameras.forEach(cameraId => {\n            const camera = this.cameras.get(cameraId);\n            if (!camera) return;\n            \n            if (cameraId === refCameraId) {\n                results[cameraId] = {\n                    offset: 0,\n                    confidence: 1.0,\n                    method: 'sync-marker-reference'\n                };\n                return;\n            }\n            \n            // Find closest sync marker\n            let closestMarker = null;\n            let closestDistance = Infinity;\n            \n            camera.syncMarkers.forEach(marker => {\n                const distance = Math.abs(marker.time - refMarker.time);\n                if (distance < closestDistance) {\n                    closestDistance = distance;\n                    closestMarker = marker;\n                }\n            });\n            \n            if (closestMarker && closestDistance <= this.config.syncMarkerTolerance) {\n                const offset = refMarker.time - closestMarker.time;\n                results[cameraId] = {\n                    offset,\n                    confidence: Math.min(closestMarker.confidence, refMarker.confidence),\n                    method: 'sync-marker',\n                    markerDistance: closestDistance\n                };\n            } else {\n                console.warn(`No suitable sync marker found for camera ${cameraId}`);\n                results[cameraId] = {\n                    offset: 0,\n                    confidence: 0,\n                    method: 'sync-marker-failed'\n                };\n            }\n        });\n        \n        this.applySyncResults(groupId, results);\n        return results;\n    }\n    \n    // Preview and Testing\n    enablePreviewMode(enabled = true) {\n        this.previewMode = enabled;\n        console.log(`Preview mode ${enabled ? 'enabled' : 'disabled'}`);\n    }\n    \n    generateTestSyncClap(durationMs = 100, frequency = 1000) {\n        const sampleCount = Math.floor((durationMs / 1000) * this.sampleRate);\n        const testBuffer = this.audioContext.createBuffer(1, sampleCount, this.sampleRate);\n        const channelData = testBuffer.getChannelData(0);\n        \n        // Generate a sharp transient (simulating hand clap)\n        for (let i = 0; i < sampleCount; i++) {\n            const t = i / this.sampleRate;\n            const envelope = Math.exp(-t * 10); // Quick decay\n            const noise = (Math.random() - 0.5) * 2;\n            const tone = Math.sin(2 * Math.PI * frequency * t);\n            \n            channelData[i] = envelope * (noise * 0.7 + tone * 0.3);\n        }\n        \n        return testBuffer;\n    }\n    \n    // Utility Functions\n    generateGroupId() {\n        return `group_${Date.now()}_${Math.floor(Math.random() * 1000)}`;\n    }\n    \n    generateMarkerId() {\n        return `marker_${Date.now()}_${Math.floor(Math.random() * 1000)}`;\n    }\n    \n    // Status and Information\n    getAlignmentStatus(trackId = null) {\n        if (trackId !== null) {\n            const camera = this.cameras.get(trackId);\n            const alignment = this.alignmentData.get(trackId);\n            \n            return {\n                camera: camera ? {\n                    name: camera.name,\n                    isReference: camera.isReference,\n                    hasAudio: !!camera.audioBuffer,\n                    syncMarkers: camera.syncMarkers.length\n                } : null,\n                alignment: alignment ? {\n                    offset: alignment.offset,\n                    confidence: alignment.confidence,\n                    method: alignment.method,\n                    lastSync: alignment.lastSync\n                } : null\n            };\n        }\n        \n        // Return status for all cameras\n        const status = {\n            cameraCount: this.cameras.size,\n            syncGroupCount: this.syncGroups.size,\n            cameras: {},\n            syncGroups: {},\n            isAnalyzing: this.isSyncAnalyzing,\n            syncProgress: this.syncProgress\n        };\n        \n        this.cameras.forEach((camera, trackId) => {\n            const alignment = this.alignmentData.get(trackId);\n            status.cameras[trackId] = {\n                name: camera.name,\n                isReference: camera.isReference,\n                hasAudio: !!camera.audioBuffer,\n                syncMarkers: camera.syncMarkers.length,\n                offset: alignment?.offset || 0,\n                confidence: alignment?.confidence || 0,\n                method: alignment?.method || 'none'\n            };\n        });\n        \n        this.syncGroups.forEach((group, groupId) => {\n            status.syncGroups[groupId] = {\n                name: group.name,\n                cameras: group.cameras,\n                referenceCamera: group.referenceCamera,\n                lastSync: group.lastSync\n            };\n        });\n        \n        return status;\n    }\n    \n    exportAlignment() {\n        const alignmentExport = {\n            timestamp: Date.now(),\n            cameras: {},\n            syncGroups: {},\n            config: this.config\n        };\n        \n        this.cameras.forEach((camera, trackId) => {\n            const alignment = this.alignmentData.get(trackId);\n            alignmentExport.cameras[trackId] = {\n                name: camera.name,\n                timecode: camera.timecode,\n                frameRate: camera.frameRate,\n                syncMarkers: camera.syncMarkers,\n                alignment: alignment ? {\n                    offset: alignment.offset,\n                    confidence: alignment.confidence,\n                    method: alignment.method,\n                    syncHistory: alignment.syncHistory\n                } : null\n            };\n        });\n        \n        this.syncGroups.forEach((group, groupId) => {\n            alignmentExport.syncGroups[groupId] = {\n                name: group.name,\n                cameras: group.cameras,\n                referenceCamera: group.referenceCamera,\n                syncMethod: group.syncMethod,\n                settings: group.settings\n            };\n        });\n        \n        return alignmentExport;\n    }\n    \n    importAlignment(alignmentData) {\n        try {\n            // Clear existing data\n            this.cameras.clear();\n            this.syncGroups.clear();\n            this.alignmentData.clear();\n            \n            // Import cameras\n            Object.entries(alignmentData.cameras).forEach(([trackId, cameraData]) => {\n                this.addCamera(parseInt(trackId), {\n                    name: cameraData.name,\n                    timecode: cameraData.timecode,\n                    frameRate: cameraData.frameRate,\n                    syncMarkers: cameraData.syncMarkers || []\n                });\n                \n                if (cameraData.alignment) {\n                    const alignment = this.alignmentData.get(parseInt(trackId));\n                    if (alignment) {\n                        Object.assign(alignment, cameraData.alignment);\n                    }\n                }\n            });\n            \n            // Import sync groups\n            Object.entries(alignmentData.syncGroups).forEach(([groupId, groupData]) => {\n                this.syncGroups.set(groupId, {\n                    ...groupData,\n                    id: groupId,\n                    created: Date.now(),\n                    lastSync: null\n                });\n            });\n            \n            console.log('Alignment data imported successfully');\n            return true;\n            \n        } catch (error) {\n            console.error('Failed to import alignment data:', error);\n            return false;\n        }\n    }\n    \n    // Event System\n    on(event, handler) {\n        if (!this.eventHandlers[event]) {\n            this.eventHandlers[event] = [];\n        }\n        this.eventHandlers[event].push(handler);\n    }\n    \n    off(event, handler) {\n        if (this.eventHandlers[event]) {\n            const index = this.eventHandlers[event].indexOf(handler);\n            if (index > -1) {\n                this.eventHandlers[event].splice(index, 1);\n            }\n        }\n    }\n    \n    emit(event, data) {\n        if (this.eventHandlers[event]) {\n            this.eventHandlers[event].forEach(handler => {\n                try {\n                    handler(data);\n                } catch (error) {\n                    console.error(`Error in event handler for ${event}:`, error);\n                }\n            });\n        }\n    }\n    \n    // Cleanup\n    destroy() {\n        this.isSyncAnalyzing = false;\n        this.cameras.clear();\n        this.syncGroups.clear();\n        this.alignmentData.clear();\n        \n        console.log('Multi-camera audio aligner destroyed');\n    }\n}\n\nexport default MultiCamAudioAligner;"
